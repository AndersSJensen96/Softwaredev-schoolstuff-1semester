{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PosterEksample.ipynb","provenance":[{"file_id":"1ddWUDv7v_UQRNulXzmwCiIZzway0vXt3","timestamp":1653302244201},{"file_id":"1dn2m--ETbXm10zvY0u4DcwdiPcX_UHN6","timestamp":1652087746566}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h51eusoqLO16","executionInfo":{"status":"ok","timestamp":1653302842266,"user_tz":-120,"elapsed":22637,"user":{"displayName":"Nicolai Renbo Svane Sparvath","userId":"06485847191379648053"}},"outputId":"ec0c8845-5783-4ee8-bd4a-14948c5ac8d6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import torch\n","import cv2\n","import numpy as np\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset\n","import pandas as pd\n","\n","currentDirPath = \"./drive/MyDrive/Software udvikling/DeepLearning/Eksamen/\""],"metadata":{"id":"QqUHSMkqQQbK","executionInfo":{"status":"ok","timestamp":1653302895704,"user_tz":-120,"elapsed":846,"user":{"displayName":"Nicolai Renbo Svane Sparvath","userId":"06485847191379648053"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":88,"metadata":{"id":"PzI_YXOoiBlF","executionInfo":{"status":"ok","timestamp":1653305212810,"user_tz":-120,"elapsed":2,"user":{"displayName":"Nicolai Renbo Svane Sparvath","userId":"06485847191379648053"}}},"outputs":[],"source":["class ImageDataset(Dataset):\n","    def __init__(self, csv, train, test):\n","        self.csv = csv\n","        self.train = train\n","        self.test = test\n","        self.all_image_names = self.csv[:]['img_id']\n","        self.all_labels = np.array(self.csv.drop(['img_id', 'text', 'Numbers'], axis=1))\n","        self.train_ratio = int(0.85 * len(self.csv))\n","        self.valid_ratio = len(self.csv) - self.train_ratio\n","        # set the training data images and labels\n","        if self.train == True:\n","            print(f\"Number of training images: {self.train_ratio}\")\n","            self.image_names = list(self.all_image_names[:self.train_ratio])\n","            self.labels = list(self.all_labels[:self.train_ratio])\n","            # define the training transforms\n","            self.transform = transforms.Compose([\n","                transforms.ToPILImage(),\n","                transforms.Resize((400, 400)),\n","                transforms.RandomHorizontalFlip(p=0.5),\n","                transforms.RandomRotation(degrees=45),\n","                transforms.ToTensor(),\n","            ])\n","        # set the validation data images and labels\n","        elif self.train == False and self.test == False:\n","            print(f\"Number of validation images: {self.valid_ratio}\")\n","            self.image_names = list(self.all_image_names[-self.valid_ratio:-10])\n","            self.labels = list(self.all_labels[-self.valid_ratio:])\n","            # define the validation transforms\n","            self.transform = transforms.Compose([\n","                transforms.ToPILImage(),\n","                transforms.Resize((400, 400)),\n","                transforms.ToTensor(),\n","            ])\n","        # set the test data images and labels, only last 10 images\n","        # this, we will use in a separate inference script\n","        elif self.test == True and self.train == False:\n","            self.image_names = list(self.all_image_names[-10:])\n","            self.labels = list(self.all_labels[-10:])\n","             # define the test transforms\n","            self.transform = transforms.Compose([\n","                transforms.ToPILImage(),\n","                transforms.ToTensor(),\n","            ])\n","    def __len__(self):\n","        return len(self.image_names)\n","    \n","    def __getitem__(self, index):\n","        image = cv2.imread(currentDirPath + f\"TrainingData/D2/Images/{self.image_names[index]}\")\n","        # convert the image from BGR to RGB color format\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        # apply image transforms\n","        image = self.transform(image)\n","        targets = self.labels[index]\n","        \n","        return {\n","            'image': torch.tensor(image, dtype=torch.float32),\n","            'label': torch.tensor(targets, dtype=torch.float32)\n","        }"]},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","\n","csv = pd.read_csv(currentDirPath + \"TrainingData/D2/D2.csv\")\n","\n","dropList = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n","#print(csv.loc[0][1])\n","array = []\n","zeroCombined = []\n","oneCombined = []\n","twoCombined = []\n","threeCombined = []\n","fourCombined = []\n","fiveCombined = []\n","sixCombined = []\n","sevenCombined = []\n","eightCombined = []\n","nineCombined = []\n","\n","for index, row in csv.iterrows():\n","  oneHotNumbers = [0,0,0,0,0,0,0,0,0,0]\n","  zeroArray = 0\n","  oneArray = 0\n","  twoArray = 0\n","  threeArray = 0\n","  fourArray = 0\n","  fiveArray = 0\n","  sixArray = 0\n","  sevenArray = 0\n","  eightArray = 0\n","  nineArray = 0\n","  for char in row['text']:\n","    if char.isdigit():\n","      if int(char) == 0:\n","        oneHotNumbers[0] = 1\n","        zeroArray = 1\n","\n","      if int(char) == 1:\n","        oneHotNumbers[1] = 1\n","        oneArray = 1\n","\n","      if int(char) == 2:\n","        oneHotNumbers[2] = 1\n","        twoArray = 1\n","\n","      if int(char) == 3:\n","        oneHotNumbers[3] = 1\n","        threeArray = 1\n","\n","      if int(char) == 4:\n","        oneHotNumbers[4] = 1\n","        fourArray = 1\n","\n","      if int(char) == 5:\n","        oneHotNumbers[5] = 1\n","        fiveArray = 1\n","\n","      if int(char) == 6:\n","        oneHotNumbers[6] = 1\n","        sixArray = 1\n","\n","      if int(char) == 7:\n","        oneHotNumbers[7] = 1\n","        sevenArray = 1\n","\n","      if int(char) == 8:\n","        oneHotNumbers[8] = 1\n","        eightArray = 1\n","\n","      if int(char) == 9:\n","        oneHotNumbers[9] = 1\n","        nineArray = 1\n","\n","  array.append(oneHotNumbers)\n","  zeroCombined.append(zeroArray)\n","  oneCombined.append(oneArray)\n","  twoCombined.append(twoArray)\n","  threeCombined.append(threeArray)\n","  fourCombined.append(fourArray)\n","  fiveCombined.append(fiveArray)\n","  sixCombined.append(sixArray)\n","  sevenCombined.append(sevenArray)\n","  eightCombined.append(eightArray)\n","  nineCombined.append(nineArray)\n","\n","\n","df = pd.DataFrame({\"Numbers\": array})\n","final_df = csv.join(df)\n","\n","dfZero = pd.DataFrame({0: zeroCombined})\n","final_df = final_df.join(dfZero)\n","\n","dfOne = pd.DataFrame({1: oneCombined})\n","final_df = final_df.join(dfOne)\n","\n","dfTwo = pd.DataFrame({2: twoCombined})\n","final_df = final_df.join(dfTwo)\n","\n","dfThree = pd.DataFrame({3: threeCombined})\n","final_df = final_df.join(dfThree)\n","\n","dfFour = pd.DataFrame({4: fourCombined})\n","final_df = final_df.join(dfFour)\n","\n","dfFive = pd.DataFrame({5: fiveCombined})\n","final_df = final_df.join(dfFive)\n","\n","dfSix = pd.DataFrame({6: sixCombined})\n","final_df = final_df.join(dfSix)\n","\n","dfSeven = pd.DataFrame({7: sevenCombined})\n","final_df = final_df.join(dfSeven)\n","\n","dfEight = pd.DataFrame({8: eightCombined})\n","final_df = final_df.join(dfEight)\n","\n","dfNine = pd.DataFrame({9: nineCombined})\n","final_df = final_df.join(dfNine)\n","\n","final_df.to_csv(currentDirPath + \"TrainingData/D2/D2_OHE.csv\", index=False)\n","\n","\n","# for index, row in csv.iterrows():\n","#     print(row['c1'], row['c2'])"],"metadata":{"id":"UdQ1dYqjAPzN","executionInfo":{"status":"ok","timestamp":1653305215183,"user_tz":-120,"elapsed":351,"user":{"displayName":"Nicolai Renbo Svane Sparvath","userId":"06485847191379648053"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["from torchvision import models as models\n","import torch.nn as nn\n","def mymodel(pretrained, requires_grad):\n","    model = models.resnet50(progress=True, pretrained=pretrained)\n","    # to freeze the hidden layers\n","    if requires_grad == False:\n","        for param in model.parameters():\n","            param.requires_grad = False\n","    # to train the hidden layers\n","    elif requires_grad == True:\n","        for param in model.parameters():\n","            param.requires_grad = True\n","    # make the classification layer learnable\n","    # we have 25 classes in total\n","    model.fc = nn.Linear(2048, 10)\n","    return model"],"metadata":{"id":"p9R8gwTnt93J","executionInfo":{"status":"ok","timestamp":1653305217859,"user_tz":-120,"elapsed":347,"user":{"displayName":"Nicolai Renbo Svane Sparvath","userId":"06485847191379648053"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["import torch\n","from tqdm import tqdm\n","# training function\n","def train(model, dataloader, optimizer, criterion, train_data, device):\n","    print('Training')\n","    model.train()\n","    counter = 0\n","    train_running_loss = 0.0\n","    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n","        counter += 1\n","        data, target = data['image'].to(device), data['label'].to(device)\n","        optimizer.zero_grad()\n","        outputs = model(data)\n","        # apply sigmoid activation to get all the outputs between 0 and 1\n","        outputs = torch.sigmoid(outputs)\n","        loss = criterion(outputs, target)\n","        train_running_loss += loss.item()\n","        # backpropagation\n","        loss.backward()\n","        # update optimizer parameters\n","        optimizer.step()\n","        \n","    train_loss = train_running_loss / counter\n","    return train_loss"],"metadata":{"id":"t0XINiLyVnot","executionInfo":{"status":"ok","timestamp":1653305219777,"user_tz":-120,"elapsed":336,"user":{"displayName":"Nicolai Renbo Svane Sparvath","userId":"06485847191379648053"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["# validation function\n","def validate(model, dataloader, criterion, val_data, device):\n","    print('Validating')\n","    model.eval()\n","    counter = 0\n","    val_running_loss = 0.0\n","    with torch.no_grad():\n","        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)/dataloader.batch_size)):\n","            counter += 1\n","            data, target = data['image'].to(device), data['label'].to(device)\n","            outputs = model(data)\n","            # apply sigmoid activation to get all the outputs between 0 and 1\n","            outputs = torch.sigmoid(outputs)\n","            loss = criterion(outputs, target)\n","            val_running_loss += loss.item()\n","        \n","        val_loss = val_running_loss / counter\n","        return val_loss"],"metadata":{"id":"QIjzQqy5ZAhP","executionInfo":{"status":"ok","timestamp":1653305221229,"user_tz":-120,"elapsed":1,"user":{"displayName":"Nicolai Renbo Svane Sparvath","userId":"06485847191379648053"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib\n","\n","from torch.utils.data import DataLoader\n","matplotlib.style.use('ggplot')\n","# initialize the computation device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"kDyanj6ob7DM","executionInfo":{"status":"ok","timestamp":1653305222853,"user_tz":-120,"elapsed":1,"user":{"displayName":"Nicolai Renbo Svane Sparvath","userId":"06485847191379648053"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["#intialize the model\n","model = mymodel(pretrained=True, requires_grad=False).to(device)\n","# learning parameters\n","lr = 0.0001\n","epochs = 20\n","batch_size = 4\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","criterion = nn.BCELoss()"],"metadata":{"id":"KuqtAbh0cQYU","executionInfo":{"status":"ok","timestamp":1653305228861,"user_tz":-120,"elapsed":889,"user":{"displayName":"Nicolai Renbo Svane Sparvath","userId":"06485847191379648053"}}},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":["# Ny sektion"],"metadata":{"id":"umOvqMbE5Ur-"}},{"cell_type":"code","source":["# read the training csv file\n","train_csv = pd.read_csv(currentDirPath + \"TrainingData/D2/D2_OHE.csv\")\n","# train dataset\n","train_data = ImageDataset(\n","    train_csv, train=True, test=False\n",")\n","# validation dataset\n","valid_data = ImageDataset(\n","    train_csv, train=False, test=False\n",")\n","# train data loader\n","train_loader = DataLoader(\n","    train_data, \n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","# validation data loader\n","valid_loader = DataLoader(\n","    valid_data, \n","    batch_size=batch_size,\n","    shuffle=False\n",")"],"metadata":{"id":"ADGgjeuKcRrU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653305231941,"user_tz":-120,"elapsed":352,"user":{"displayName":"Nicolai Renbo Svane Sparvath","userId":"06485847191379648053"}},"outputId":"7c9cb8b0-81f3-4e0f-8935-79888032182a"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training images: 765\n","Number of validation images: 135\n"]}]},{"cell_type":"code","source":["# start the training and validation\n","train_loss = []\n","valid_loss = []\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1} of {epochs}\")\n","    train_epoch_loss = train(\n","        model, train_loader, optimizer, criterion, train_data, device\n","    )\n","    valid_epoch_loss = validate(\n","        model, valid_loader, criterion, valid_data, device\n","    )\n","    train_loss.append(train_epoch_loss)\n","    valid_loss.append(valid_epoch_loss)\n","    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n","    print(f'Val Loss: {valid_epoch_loss:.4f}')"],"metadata":{"id":"D91Z21ndcZ4-","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1653311523710,"user_tz":-120,"elapsed":6290259,"user":{"displayName":"Nicolai Renbo Svane Sparvath","userId":"06485847191379648053"}},"outputId":"4895eaa1-1b0f-45ee-df46-2d67ff1f9420"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 of 20\n","Training\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/191 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","192it [15:09,  4.74s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Validating\n"]},{"output_type":"stream","name":"stderr","text":["32it [02:54,  5.44s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6761\n","Val Loss: 0.6903\n","Epoch 2 of 20\n","Training\n"]},{"output_type":"stream","name":"stderr","text":["192it [09:58,  3.12s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Validating\n"]},{"output_type":"stream","name":"stderr","text":["32it [01:21,  2.54s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6729\n","Val Loss: 0.6850\n","Epoch 3 of 20\n","Training\n"]},{"output_type":"stream","name":"stderr","text":["192it [10:09,  3.17s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Validating\n"]},{"output_type":"stream","name":"stderr","text":["32it [01:22,  2.58s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6728\n","Val Loss: 0.6776\n","Epoch 4 of 20\n","Training\n"]},{"output_type":"stream","name":"stderr","text":["192it [10:09,  3.17s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Validating\n"]},{"output_type":"stream","name":"stderr","text":["32it [01:23,  2.61s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6712\n","Val Loss: 0.6858\n","Epoch 5 of 20\n","Training\n"]},{"output_type":"stream","name":"stderr","text":["192it [10:17,  3.21s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Validating\n"]},{"output_type":"stream","name":"stderr","text":["32it [01:23,  2.62s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6700\n","Val Loss: 0.6843\n","Epoch 6 of 20\n","Training\n"]},{"output_type":"stream","name":"stderr","text":["192it [10:09,  3.18s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Validating\n"]},{"output_type":"stream","name":"stderr","text":["32it [01:21,  2.54s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6693\n","Val Loss: 0.6863\n","Epoch 7 of 20\n","Training\n"]},{"output_type":"stream","name":"stderr","text":["192it [09:57,  3.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Validating\n"]},{"output_type":"stream","name":"stderr","text":["32it [01:21,  2.53s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6680\n","Val Loss: 0.6810\n","Epoch 8 of 20\n","Training\n"]},{"output_type":"stream","name":"stderr","text":["192it [09:54,  3.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Validating\n"]},{"output_type":"stream","name":"stderr","text":["32it [01:20,  2.52s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6686\n","Val Loss: 0.6877\n","Epoch 9 of 20\n","Training\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▌   | 125/191 [06:35<03:28,  3.16s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-96-00b9716dc8aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1} of {epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     train_epoch_loss = train(\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m     valid_epoch_loss = validate(\n","\u001b[0;32m<ipython-input-91-c504b8bc5811>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion, train_data, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m# apply sigmoid activation to get all the outputs between 0 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2422\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2423\u001b[0m     )\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# save the trained model to disk\n","torch.save({\n","            'epoch': epochs,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': criterion,\n","            }, currentDirPath + \"TrainingData/D2/\"+ 'outputs/model.pth')\n","# plot and save the train and validation line graphs\n","plt.figure(figsize=(10, 7))\n","plt.plot(train_loss, color='orange', label='train loss')\n","plt.plot(valid_loss, color='red', label='validataion loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.savefig('../outputs/loss.png')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"55MU-GHMcbzl","executionInfo":{"status":"error","timestamp":1653311527041,"user_tz":-120,"elapsed":3,"user":{"displayName":"Nicolai Renbo Svane Sparvath","userId":"06485847191379648053"}},"outputId":"751e6cc8-364c-4777-f0dc-a4012452c49a"},"execution_count":97,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-97-e450febcc73f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             }, currentDirPath + \"TrainingData/D2/\"+ 'outputs/model.pth')\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# plot and save the train and validation line graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './drive/MyDrive/Software udvikling/DeepLearning/Eksamen/TrainingData/D2/outputs/model.pth'"]}]}]}